# LiteLLM Configuration for Tales of Charlie
# This file defines model routing, budget controls, and caching for AI integration

# General settings
general_settings:
  master_key: ${LITELLM_MASTER_KEY}
  database_url: ${LITELLM_DATABASE_URL} # Optional: for persistent budget tracking

# Model list - OpenAI GPT-5 (latest and most advanced model) only
model_list:
  - model_name: gpt-5
    litellm_params:
      model: openai/gpt-5
      api_key: ${OPENAI_API_KEY}
      timeout: 60
      max_tokens: 2000
      temperature: 0.3

# Router settings
router_settings:
  routing_strategy: simple-shuffle # Single model - no actual routing needed

# Budget and rate limiting
budget_settings:
  max_budget: ${MAX_DAILY_COST_USD}
  budget_duration: "1d"
  budget_reset: "00:00:00"

# Rate limiting per model
rate_limit:
  gpt-5:
    requests_per_minute: 30
    tokens_per_minute: 30000

# Caching configuration
cache_settings:
  type: "redis"
  host: "redis"
  port: 6379
  ttl: 1800 # Cache responses for 30 minutes

# Logging
logging_settings:
  log_level: "INFO"
  log_raw_request_response: false # Don't log content for privacy

# Success callback (for usage tracking)
success_callback: ["budget_manager"]

# Failure callback (for error tracking)
failure_callback: ["budget_manager"]

# Environment-specific overrides
environment:
  development:
    logging_settings:
      log_level: "DEBUG"
    rate_limit:
      # More relaxed limits for development
      gpt-5:
        requests_per_minute: 50
        tokens_per_minute: 50000
